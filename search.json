[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Macfarlane Lab",
    "section": "",
    "text": "Welcome!\nYou have been hired into my lab, or are about to be hired in my lab. This website is a collection of resources that my students use to get trained and learn how to do things. It is also a helpful thing for me to remember all the things I have to do."
  },
  {
    "objectID": "onboarding.html#working-hours",
    "href": "onboarding.html#working-hours",
    "title": "1  Onboarding",
    "section": "1.1 Working hours",
    "text": "1.1 Working hours\nWhen I hire you I will state expectations for a weekly commitment. This is typically:\n\nUndergraduates: 5-10 hours per week\nGraduate student academic year: 10-20 hours per week\nGraduate student Spring/Summer: 20-30 hours per week\n\nYou may work whatever hours you choose, with the exception of any weekly project team meetings or project sponsor calls. That said, I strongly recommend you schedule a regular weekly time to dedicate to the research projects you are working on. Other commitments might easily crowd out the time for your research if you do not prioritize the time. Also, I want to pay you! But I can’t if you don’t put in time.\nI strongly recommend that students who work for me as a research assistant quit any other research assistance, internship, or other external employment."
  },
  {
    "objectID": "onboarding.html#communication",
    "href": "onboarding.html#communication",
    "title": "1  Onboarding",
    "section": "1.2 Communication",
    "text": "1.2 Communication\nI use Slack for almost all lab-related communication. Please install the Slack app on your phone and your computer. I expect you to respond to messages within a reasonable amount of time, but I never expect you to respond while you are with your families or other times when you are not working.\nIf you would like to reach me with a message, use slack.\nIf you would like to meet with me in person about a brief issue, please schedule an office hour appointment using Calendly. If you would like to schedule a longer meeting with me, please schedule a research meeting appointment using Calendly."
  },
  {
    "objectID": "onboarding.html#wages",
    "href": "onboarding.html#wages",
    "title": "1  Onboarding",
    "section": "1.3 Wages",
    "text": "1.3 Wages\nStudents in my lab have their wages determined by skill and seniority, following the basic outlines of the BYU hourly pay scale. Each semester I will evaluate student work and give raises as appropriate.\nIf you believe you merit a raise or there are needs in your family that might necessitate a higher wage, please speak to me. I’ll do what I can."
  },
  {
    "objectID": "workflow.html#motivation",
    "href": "workflow.html#motivation",
    "title": "2  Project Workflow",
    "section": "2.1 Motivation",
    "text": "2.1 Motivation\nThe goal of this workflow is to allow you to work effectively in my lab, and to ensure that I and future students (including yourself!) know where things are and can rebuild them if necessary. For example, a peer reviewer may ask for changes to the analysis many months after you are gone. If you follow this workflow, the chances of me being able to productively use your work increase.\nA workflow that you have probably used in the past consists of:\n\nKeep data in a spreadsheet (Excel)\nDo your analysis in the same spreadsheet\nCopy a table or numbers from a spreadsheet into a document (Word)\nWrite about the analysis in Word\n\nThis workflow has its benefits, mainly simplicity. Excel definitely has its place. But there are lots of drawbacks.\nFirst, spreadsheets tend to hide formulae or make them very difficult to read. For example, JP Morgan Chase bank lost almost $6 Billion when a trader believed a formula in an excel spreadsheet that he couldn’t see the error in, because the formula wasn’t shown. It would be better to have clearly written methods and analysis, than to just show the numbers that go in that analysis.\nSecond, this method can rely on lots of manual tasks: push this button, copy this figure, update this number. Doing it once is easy, but what if I ask you to go back and change something? Will you remember every table that depends on that calculation? Or what if you leave and another student has to figure out what you did? It would be better to have a reproducible document that re-builds itself whenever the analysis changes.\nThis is the problem that R and R markdown solves. For example, I can embed R code into this document. I can load a library, read a dataset, and create a figure all at once.\n\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) + \n  geom_point()\n\n\n\n\nAnd if I tell you that I’d rather see a different figure, you can just change the code and it will print something different\n\nggplot(mpg, aes(hwy, fill = class)) + \n  geom_density(alpha = 0.5) + theme_bw()\n\n\n\n\nSo, how do you make this happen?"
  },
  {
    "objectID": "workflow.html#sec-r-projects",
    "href": "workflow.html#sec-r-projects",
    "title": "2  Project Workflow",
    "section": "2.2 R Projects",
    "text": "2.2 R Projects\nThe basis of every project — a paper, thesis, or report — should be an R project. An R project is a folder associated with an .Rproj file that can be created and opened in R Studio. For an introduction to installing R and Rstudio, there is a tutorial at DataCamp.\nThe R project folder should be organized into these subfolders as follows:\n<project>/\n  - README.md\n  - <project.Rproj>\n  - data/\n  - R/\n  - py/\n  - ....\n\nREADME.md is a markdown file that describes what the project is about. What is the central question, who is the project sponsor, and what other data resources might need to be referenced in the project.\ndata/ is the folder where you place all of your input or intermediate data. There may be subfolders in this folder. Preference is for plain text (csv or json) data over data stored in spreadsheets or binary formats. If you get data from the internet, it might be better to write code to download the data instead of storing the downloaded data. That would be more reproducible.\nR/ is a folder where you write your R scripts. Each script should be clearly named, e.g., data_cleaning.R .\npy/ is a folder where you write your python scripts. Each script should be clearly named, e.g., data_cleaning.py .\n\nWhen you type a path in a script, it should reference its location relative to the folder root. So a script in R/clean_data.R might look like this:\n# read data from folder\ndata <- read_csv(\"data/my_data.csv\")\nThis lets other people who work on your project use it without changing all the paths to the all the files that you use. Or as Jenny Bryan put it,\n\nIf the first line of your #rstats script issetwd(\"C:\\Users\\jenny\\path\\that\\only\\I\\have\"), I will come into your lab and SET YOUR COMPUTER ON FIRE.\n\nOther folders might be useful, but should be carefully named and organized.1 Additionally, it might be a good idea to put README file in some of the sub-folders if the information in them might need more explanation.\n\nThe LinkedIn Learning Course R: Essential Training: Wrangling and Visualizing Data shows how to implement this folder structure and an R Studio project\nFor an introduction to installing R and R Studio, there is a tutorial at DataCamp. Follow along with the tutorial if you are new to R and R Studio.\nIf you are curious about projects, there is a helpful R Studio resource page with instructions on how they work."
  },
  {
    "objectID": "workflow.html#git-and-github",
    "href": "workflow.html#git-and-github",
    "title": "2  Project Workflow",
    "section": "2.3 Git and GitHub",
    "text": "2.3 Git and GitHub\nYour project directory should be a git repository that is posted to GitHub.\nGit is software that tracks changes to plain text documents line-by-line, over time. It also provides robust methods for merging conflicting documents written by different users. No longer will you need to have a folder that contains the following:\nmy_document.docx\nmy_document edits from advisor.docx\nmy_document final.docx\nmy_documentREALLYFINAL.docx\nmy_documentREALLYFINAL_edits from advisor.docx\nWhen used correctly with good commit messages, git can serve as an excellent lab notebook for the project. Some basic rules for working with git:\n\nCommit regularly Keep your working directory clean! Don’t let dozens of different changes pile up between commits\nWrite good messages A good commit message will help you and me trace what is going on, and see what matters. A primer on writing good messages is here; learn this and do it consistently!\nIgnore files correctly If it is a file that you actually worked on, then it should be committed and tracked. But if you don’t know what it is, then there’s a good chance that it was created as a byproduct and should be ignored. You don’t want hundreds of files clogging up your git commit list. Also, any project data that is not supposed to be distributed must be ignored.\n\nGitHub is a web service that hosts git repositories, allowing git users to share code with each other and back it up on the internet. You are welcome to create private repositories for your own use and exploration, but work done for the lab should be in the BYU-Transpolab organization. Repositories can be public if possible or private if necessary; speak to me about what your project requires.\n\nThe LinkedIn Learning Course Learning Git and Github provides a clear tutorial with installation instructions and basic commands.\nJenny Bryan has an excellent book / course on using Git and GitHub with R, called Happy Git and GitHub for the userR. Follow these instructions."
  },
  {
    "objectID": "workflow.html#box",
    "href": "workflow.html#box",
    "title": "2  Project Workflow",
    "section": "2.4 Box",
    "text": "2.4 Box\nThere are some kinds of documents that do not lend themselves very naturally to Git/ GitHub. Word documents and power point presentations — for example — cannot be tracked line-by-line with Git. GitHub also has a 50 MB soft file size limit (and a 100 MB hard limit).\nBYU has given you free access to unlimited space on Box. I may create a folder that you use for a project, or you might create a folder and invite me to it. Folders should be organized with the same data/ README, etc. file structure as described in R Projects.\nIf your project uses large data that cannot be stored in Git, I recommend including a script that will download a file from Box directly into your local data/ folder."
  },
  {
    "objectID": "workflow.html#r-markdown-quarto",
    "href": "workflow.html#r-markdown-quarto",
    "title": "2  Project Workflow",
    "section": "2.5 R Markdown / Quarto",
    "text": "2.5 R Markdown / Quarto\nR Markdown and Quarto are technologies for embedding analysis code inside of documents. Many examples of my work are available written in R Markdown. This includes things like the textbook for CE 361 and a number of my academic papers. One set of source documents can be used to create a website, a word document, and a journal-formatted PDF file.\nA newer technology called Quarto somewhat easier to work with, and can process code written in R, python, or any number of other languages. There is a comprehensive authoring guide to Quarto; read this guide and refer to it.\n\nI have written a template GitHub repository that generates a bookdown website and Elsevier journal article. I hope to create a similar template for Quarto in the near future.\nUsing the cosmodown package, you can set up a template to make your BYU Engineering thesis in bookdown. A Quarto template may come soon.\nA linkedin Learning Course, Creating Reports and Presentations with R Markdown and RStudio will help you learn these techniques."
  },
  {
    "objectID": "workflow.html#targets",
    "href": "workflow.html#targets",
    "title": "2  Project Workflow",
    "section": "2.6 Targets",
    "text": "2.6 Targets\nOne reason to script your work instead of use button-pushing software is so you can repeat it. But while you are working, it sometimes becomes difficult to remember which sections of your code you have to re-run when you update something. It also might take a long time to re-run your analysis if you have costly steps.\nFor small projects where all the calculations can occur on render, it makes sense to just have all the code embedded in the document. Many times, however, you will have heavy calculations that you don’t want to run every time you typeset your document. The targets package allows you to build a pipeline that runs your work in order and keeps track of what has been run and what has not been run. The core of targets is a _targets.R R script that looks something like this:\n# _targets.R file\nlibrary(targets)\nsource(\"R/functions.R\")\ntar_option_set(packages = c(\"readr\", \"dplyr\", \"ggplot2\"))\nlist(\n  # Start with data --------\n  # format = \"file\" means that every time data.csv changes, pipeline will run \n  # again\n  tar_target(file, \"data.csv\", format = \"file\"),  \n  \n  # Read data into workspace\n  tar_target(data, get_data(file)),\n  \n  # fit model based on data\n  tar_target(model, fit_model(data)),\n  \n  # make a plot based on the model\n  tar_target(plot, plot_model(model, data))\n)\nIn the R/functions.R file, there will be functions called get_data , fit_model, and plot_model that tell R what to do. When you run tar_make() in your R project, it will run all four steps. But if you change fit_model() and run tar_make() again, targets knows to skip the file and data because those have not changed.\nTargets works by storing intermediate objects in a folder called _targets/. You should ignore this file from your GitHub repository.\n\n2.6.1 Targets and Box files\nTargets is a great way to link large files stored on Box and an R project. Say that data.csv from the example above is too large to commit to GitHub. We could change the target to be\n# Start with data --------\n# format = \"file\" means that every time data.csv changes, pipeline will run \n# again\ntar_target(file, fetch_file(\"data.csv\"), format = \"file\")\nAnd then write a function that downloads the appropriate file from Box,\n#' Get data file from Box\n#' \n#' @param file Path to file\n#' \nfetch_file <- function(file){\n  # check if file is already here for some reason\n  if(!file.exists(file)){\n    # get the location for the direct download from box.\n    download.file(\"https://byu.box.com/shared/static/<code>.csv\", file)\n  } else {\n    message(\"File already exists\")\n  }\n  \n  # targets has to return something, in this case the path to the file\n  return(file)\n}\nThe Box code must be the link for the direct download. Please see the Box manual for instructions on creating and using this link.\nNote that you should not use the above method for data objects that must be protected. Instead, you could prompt the user to go to a URL and then they could download the file themselves if they had access to the box folder. Not automatically reproducible with one click, but it prompts people to go to the right place. The function below shows how to do this.\n#' Get streetlight data\n#' \n#' @param path Path to folder containing streetlight data files\n#' @param landuse One of \"libraries\", \"parks\" or \"groceries\" indicating which \n#'   land use streetlight file to download\n#'   \n#' @details We are unable to distribute the streetlight data files. This\n#'  function prompts the user to navigate to the folder on box, download \n#'  the file, and save it in the proper place before moving forward.\n#' \n#' \nget_sl_data <- function(path, landuse){\n  \n  urls <- list(\n    \"libraries\" = \"https://byu.box.com/s/<code>\",\n    \"parks\"     = \"https://byu.box.com/s/<code>\",\n    \"groceries\" = \"https://byu.box.com/s/<code>\"\n  )\n  \n  files <- list(\n    \"libraries\" = \"160756_Libraries_home_block_groups_all.csv\",\n    \"parks\"     = \"streetlight_parks.zip\",\n    \"groceries\" = \"256055_Grocery_Stores_Utah_County_2019_home_block_groups_all.csv\"\n  )\n  \n  if(!file.exists(path)){\n    message(str_c(\n      \"You need to download a file on Box.\\n\",\n      \"1. Go to \", urls[[landuse]], \"\\n\",\n      \"2. Log in to Box, and download the file.\\n\", \n      \"3. Copy the file to \", path, \"\\n\",\n      \"4. Run tar_make() again.\"))\n    stop(path, \" not Found\")\n  } else {\n    message(path, \" available\")\n  }\n  return(path) # to use file target, need to return path to data. \n  \n}"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  }
]